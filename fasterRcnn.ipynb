{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fasterRcnn.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"U3HMQn2KvT9g","colab_type":"code","outputId":"a55066d0-cc70-4ff5-fd5c-09953cf7fc46","executionInfo":{"status":"ok","timestamp":1575058677872,"user_tz":300,"elapsed":3915,"user":{"displayName":"Sai Ajay Modukuri","photoUrl":"","userId":"17635723199292011454"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["#!pip install tensorflow --upgrade\n","from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","from torchvision import transforms\n","from torch import nn\n","import torch\n","import pandas as pd\n","import os\n","import os.path\n","from PIL import Image\n","from torchvision import models\n","from tensorflow import summary\n","import datetime\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torchsummary\n","import datetime\n","import json\n","import cv2\n","import itertools\n","%load_ext tensorboard"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"K2T4IG99veom","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qjk5GAKYC6MP","colab_type":"code","colab":{}},"source":["%%shell\n","\n","# Install pycocotools\n","git clone https://github.com/cocodataset/cocoapi.git >/dev/null\n","cd cocoapi/PythonAPI\n","python setup.py build_ext install>\n","%%shell\n","\n","# Download TorchVision repo to use some files from\n","# references/detection\n","git clone https://github.com/pytorch/vision.git\n","cd vision\n","git checkout v0.3.0\n","\n","cp references/detection/utils.py ../\n","cp references/detection/transforms.py ../\n","cp references/detection/coco_eval.py ../\n","cp references/detection/engine.py ../\n","cp references/detection/coco_utils.py ../"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"goCgWKDHgjWb","colab_type":"code","colab":{}},"source":["%%shell\n","\n","cd vision\n","cp references/detection/utils.py ../\n","cp references/detection/transforms.py ../\n","cp references/detection/coco_eval.py ../\n","cp references/detection/engine.py ../\n","cp references/detection/coco_utils.py ../"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MfQJZAPyvPT1","colab_type":"code","colab":{}},"source":["import transforms\n","class ZebraDataset(Dataset):\n","  def __init__(self, path, jfile, transform = None):\n","    self.transform = transform\n","    self.path = path\n","    self.data = []\n","    dataset_dicts = []\n","    json_file = os.path.join(path, jfile)\n","    with open(json_file) as f:\n","        imgs_anns = json.load(f)\n","\n","    for _, v in imgs_anns.items():\n","        record = {}\n","        annos = v[\"regions\"]\n","        if not annos:\n","          continue\n","\n","        filename = os.path.join(path, v[\"filename\"])\n","        height, width = cv2.imread(filename).shape[:2]\n","        \n","        record[\"file_name\"] = filename\n","        record[\"height\"] = height\n","        record[\"width\"] = width\n","      \n","        annos = v[\"regions\"]\n","        objs = []\n","        for _, anno in annos.items():\n","            #not anno[\"region_attributes\"]\n","            classattr = anno[\"region_attributes\"]\n","            anno = anno[\"shape_attributes\"]\n","            px = anno[\"all_points_x\"]\n","            py = anno[\"all_points_y\"]\n","            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n","            poly = list(itertools.chain.from_iterable(poly))\n","            if not classattr:\n","                cls = 0\n","            else :\n","                cls = int(classattr[\"class\"])\n","\n","            obj = {\n","                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n","                \"segmentation\": [poly],\n","                \"category_id\": cls,\n","\n","                \"iscrowd\": 0\n","            }\n","            objs.append(obj)\n","        record[\"annotations\"] = objs\n","        dataset_dicts.append(record)\n","    self.data = dataset_dicts[1:]\n","    \n","  \n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self,id):\n","    data = self.data[id]\n","    file = Image.open(os.path.join(self.path,data[\"file_name\"])).convert('RGB')\n","    target={}\n","    boxes = []\n","    label=[]\n","    for ann in data[\"annotations\"]:\n","      boxes.append(ann[\"bbox\"])\n","      label.append(int(ann[\"category_id\"]))\n","    \n","    #print(len(boxes),len(label))\n","    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n","    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n","    image_id = torch.tensor([id])\n","    target[\"boxes\"] = boxes\n","    target[\"lables\"] = torch.as_tensor(label, dtype=torch.int32)\n","    target[\"image_id\"] = image_id\n","    target[\"area\"] = (boxes[:,3] - boxes[:,1]) * (boxes[:,2] - boxes[:,0])\n","    target[\"iscrowd\"] = torch.zeros(len(data[\"annotations\"]))\n","    \n","\n","\n","    if self.transform is not None:\n","      file, target = self.transform(file,target)\n","    return file, target"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fAArvjHbya_c","colab_type":"code","colab":{}},"source":["root = \"/content/drive/My Drive/Colab Notebooks/data/images/gray\"\n","jfile = \"set 1-125.json\"\n","trans = transforms.Compose(\n","   [ transforms.ToTensor(),\n","    transforms.Normalize([0.485], [0.229])]\n","    )\n","z=ZebraDataset(root,jfile=jfile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VXzqOu850j2D","colab_type":"code","colab":{}},"source":["import torchvision\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","\n","# load a model pre-trained pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","\n","# replace the classifier with a new one, that has\n","# num_classes which is user-defined\n","num_classes = 5  # 1 class (person) + background\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJMsi3pQPLs0","colab_type":"code","colab":{}},"source":["from engine import train_one_epoch, evaluate\n","import utils\n","import transforms as T\n","\n","\n","def get_transform(train):\n","    transforms = []\n","    # converts the image, a PIL image, into a PyTorch Tensor\n","    transforms.append(T.ToTensor())\n","    if train:\n","        # during training, randomly flip the training images\n","        # and ground-truth for data augmentation\n","        transforms.append(T.RandomHorizontalFlip(0.5))\n","    return T.Compose(transforms)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IrrT3HwvPQXC","colab_type":"code","colab":{}},"source":["device = torch.device('cuda')\n","num_classes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ty1QuvFPVb5","colab_type":"code","colab":{}},"source":[" z = ZebraDataset(root,jfile,get_transform(train=True))\n"," data_loader = torch.utils.data.DataLoader(\n","        z, batch_size=2, shuffle=True, num_workers=4,\n","        )\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1QCBgBTHAqSz","colab_type":"code","colab":{}},"source":["import torch.optim\n","model = model.to(device)\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005,\n","                                momentum=0.9, weight_decay=0.0005)\n","\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n","                                                   step_size=3,\n","                                                   gamma=0.1)\n","z.__getitem__(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnGlQgr6A3Qt","colab_type":"code","colab":{}},"source":["num_epochs = 16\n","import utils\n","\n","#from engine import train_one_epoch, evaluate\n","for epoch in range(num_epochs):\n","  # train for one epoch, printing every 10 iterations\n","  train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n","  # update the learning rate\n","  lr_scheduler.step()\n","  # evaluate on the test dataset\n","  #evaluate(model, data_loader_test, device=device)\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oonmj9hoBrQO","colab_type":"code","colab":{}},"source":["def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n","    model.train()\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n","    header = 'Epoch: [{}]'.format(epoch)\n","\n","    lr_scheduler = None\n","    if epoch == 0:\n","        warmup_factor = 1. / 1000\n","        warmup_iters = min(1000, len(data_loader) - 1)\n","\n","        lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n","\n","    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n","        images = list(image.to(device) for image in images)\n","        tar={}\n","        tar = {k: v.to(device) for k, v in targets.items()}\n","        targets = tar\n","        print(\"loss\", images.shape, type(tar), tar)\n","        loss_dict = model(images, targets)\n","\n","        losses = sum(loss for loss in loss_dict.values())\n","\n","        # reduce losses over all GPUs for logging purposes\n","        loss_dict_reduced = utils.reduce_dict(loss_dict)\n","        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n","\n","        loss_value = losses_reduced.item()\n","\n","        if not math.isfinite(loss_value):\n","            print(\"Loss is {}, stopping training\".format(loss_value))\n","            print(loss_dict_reduced)\n","            sys.exit(1)\n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","\n","        if lr_scheduler is not None:\n","            lr_scheduler.step()\n","\n","        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n","        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JErDtznsDVb_","colab_type":"code","colab":{}},"source":["def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n","    model.train()\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n","    header = 'Epoch: [{}]'.format(epoch)\n","\n","    lr_scheduler = None\n","    if epoch == 0:\n","        warmup_factor = 1. / 1000\n","        warmup_iters = min(1000, len(data_loader) - 1)\n","\n","        lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n","\n","    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n","        images = list(image.to(device) for image in images)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","\n","        losses = sum(loss for loss in loss_dict.values())\n","\n","        # reduce losses over all GPUs for logging purposes\n","        loss_dict_reduced = utils.reduce_dict(loss_dict)\n","        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n","\n","        loss_value = losses_reduced.item()\n","\n","        if not math.isfinite(loss_value):\n","            print(\"Loss is {}, stopping training\".format(loss_value))\n","            print(loss_dict_reduced)\n","            sys.exit(1)\n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","\n","        if lr_scheduler is not None:\n","            lr_scheduler.step()\n","\n","        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n","        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d43epSsspVVn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}